Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
20/04/09 21:39:51 INFO SparkContext: Running Spark version 1.5.2
20/04/09 21:39:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/04/09 21:39:52 INFO SecurityManager: Changing view acls to: sxv5264
20/04/09 21:39:52 INFO SecurityManager: Changing modify acls to: sxv5264
20/04/09 21:39:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sxv5264); users with modify permissions: Set(sxv5264)
20/04/09 21:39:52 INFO Slf4jLogger: Slf4jLogger started
20/04/09 21:39:52 INFO Remoting: Starting remoting
20/04/09 21:39:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@198.202.116.33:44167]
20/04/09 21:39:52 INFO Utils: Successfully started service 'sparkDriver' on port 44167.
20/04/09 21:39:52 INFO SparkEnv: Registering MapOutputTracker
20/04/09 21:39:52 INFO SparkEnv: Registering BlockManagerMaster
20/04/09 21:39:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-359931c7-16b0-41ec-8c8b-0b8dc2866089
20/04/09 21:39:52 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
20/04/09 21:39:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-57ede800-112d-461c-90bc-816f59b91ea2/httpd-9625a485-27e0-4dda-bb67-ecd0958fd972
20/04/09 21:39:52 INFO HttpServer: Starting HTTP Server
20/04/09 21:39:52 INFO Utils: Successfully started service 'HTTP file server' on port 34020.
20/04/09 21:39:52 INFO SparkEnv: Registering OutputCommitCoordinator
20/04/09 21:39:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/04/09 21:39:53 INFO SparkUI: Started SparkUI at http://198.202.116.33:4040
20/04/09 21:39:53 INFO SparkContext: Added JAR file:/home/sxv5264/project5/graph.jar at http://198.202.116.33:34020/jars/graph.jar with timestamp 1586493593053
20/04/09 21:39:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
20/04/09 21:39:53 INFO Executor: Starting executor ID driver on host localhost
20/04/09 21:39:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41602.
20/04/09 21:39:53 INFO NettyBlockTransferService: Server created on 41602
20/04/09 21:39:53 INFO BlockManagerMaster: Trying to register BlockManager
20/04/09 21:39:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41602 with 530.0 MB RAM, BlockManagerId(driver, localhost, 41602)
20/04/09 21:39:53 INFO BlockManagerMaster: Registered BlockManager
20/04/09 21:39:53 INFO MemoryStore: ensureFreeSpace(120040) called with curMem=0, maxMem=555755765
20/04/09 21:39:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 117.2 KB, free 529.9 MB)
20/04/09 21:39:53 INFO MemoryStore: ensureFreeSpace(12673) called with curMem=120040, maxMem=555755765
20/04/09 21:39:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.4 KB, free 529.9 MB)
20/04/09 21:39:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41602 (size: 12.4 KB, free: 530.0 MB)
20/04/09 21:39:53 INFO SparkContext: Created broadcast 0 from textFile at Graph.scala:11
20/04/09 21:39:53 INFO FileInputFormat: Total input paths to process : 1
20/04/09 21:39:54 INFO SparkContext: Starting job: collect at Graph.scala:44
20/04/09 21:39:54 INFO DAGScheduler: Registering RDD 75 (map at Graph.scala:43)
20/04/09 21:39:54 INFO DAGScheduler: Got job 0 (collect at Graph.scala:44) with 2 output partitions
20/04/09 21:39:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at Graph.scala:44)
20/04/09 21:39:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
20/04/09 21:39:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
20/04/09 21:39:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[75] at map at Graph.scala:43), which has no missing parents
20/04/09 21:39:54 INFO MemoryStore: ensureFreeSpace(3960) called with curMem=132713, maxMem=555755765
20/04/09 21:39:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 529.9 MB)
20/04/09 21:39:54 INFO MemoryStore: ensureFreeSpace(2286) called with curMem=136673, maxMem=555755765
20/04/09 21:39:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 529.9 MB)
20/04/09 21:39:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41602 (size: 2.2 KB, free: 530.0 MB)
20/04/09 21:39:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
20/04/09 21:39:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[75] at map at Graph.scala:43)
20/04/09 21:39:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
20/04/09 21:39:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2193 bytes)
20/04/09 21:39:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2193 bytes)
20/04/09 21:39:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/04/09 21:39:54 INFO Executor: Fetching http://198.202.116.33:34020/jars/graph.jar with timestamp 1586493593053
20/04/09 21:39:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
20/04/09 21:39:54 INFO Utils: Fetching http://198.202.116.33:34020/jars/graph.jar to /tmp/spark-57ede800-112d-461c-90bc-816f59b91ea2/userFiles-35141b3a-fd8f-436a-9bf8-d46eda6fee8e/fetchFileTemp1976207403761937041.tmp
20/04/09 21:39:54 INFO Executor: Adding file:/tmp/spark-57ede800-112d-461c-90bc-816f59b91ea2/userFiles-35141b3a-fd8f-436a-9bf8-d46eda6fee8e/graph.jar to class loader
20/04/09 21:39:54 INFO HadoopRDD: Input split: file:/home/sxv5264/project5/small-graph.txt:28+28
20/04/09 21:39:54 INFO HadoopRDD: Input split: file:/home/sxv5264/project5/small-graph.txt:0+28
20/04/09 21:39:54 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
20/04/09 21:39:54 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
20/04/09 21:39:54 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
20/04/09 21:39:54 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
20/04/09 21:39:54 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
20/04/09 21:39:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2254 bytes result sent to driver
20/04/09 21:39:54 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2254 bytes result sent to driver
20/04/09 21:39:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 190 ms on localhost (1/2)
20/04/09 21:39:54 INFO DAGScheduler: ShuffleMapStage 0 (map at Graph.scala:43) finished in 0.188 s
20/04/09 21:39:54 INFO DAGScheduler: looking for newly runnable stages
20/04/09 21:39:54 INFO DAGScheduler: running: Set()
20/04/09 21:39:54 INFO DAGScheduler: waiting: Set(ResultStage 1)
20/04/09 21:39:54 INFO DAGScheduler: failed: Set()
20/04/09 21:39:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 176 ms on localhost (2/2)
20/04/09 21:39:54 INFO DAGScheduler: Missing parents for ResultStage 1: List()
20/04/09 21:39:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
20/04/09 21:39:54 INFO DAGScheduler: Submitting ResultStage 1 (ShuffledRDD[76] at reduceByKey at Graph.scala:43), which is now runnable
20/04/09 21:39:54 INFO MemoryStore: ensureFreeSpace(2280) called with curMem=138959, maxMem=555755765
20/04/09 21:39:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.2 KB, free 529.9 MB)
20/04/09 21:39:54 INFO MemoryStore: ensureFreeSpace(1361) called with curMem=141239, maxMem=555755765
20/04/09 21:39:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1361.0 B, free 529.9 MB)
20/04/09 21:39:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41602 (size: 1361.0 B, free: 530.0 MB)
20/04/09 21:39:54 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
20/04/09 21:39:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[76] at reduceByKey at Graph.scala:43)
20/04/09 21:39:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
20/04/09 21:39:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 1953 bytes)
20/04/09 21:39:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 1953 bytes)
20/04/09 21:39:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
20/04/09 21:39:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
20/04/09 21:39:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
20/04/09 21:39:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
20/04/09 21:39:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
20/04/09 21:39:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/04/09 21:39:54 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1462 bytes result sent to driver
20/04/09 21:39:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1462 bytes result sent to driver
20/04/09 21:39:54 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 31 ms on localhost (1/2)
20/04/09 21:39:54 INFO DAGScheduler: ResultStage 1 (collect at Graph.scala:44) finished in 0.012 s
20/04/09 21:39:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 38 ms on localhost (2/2)
20/04/09 21:39:54 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
20/04/09 21:39:54 INFO DAGScheduler: Job 0 finished: collect at Graph.scala:44, took 0.341639 s
(4,1)
(0,1)
(6,1)
(8,1)
(2,1)
(1,1)
(3,1)
(7,1)
(9,1)
(5,1)
20/04/09 21:39:54 INFO SparkUI: Stopped Spark web UI at http://198.202.116.33:4040
20/04/09 21:39:54 INFO DAGScheduler: Stopping DAGScheduler
20/04/09 21:39:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/04/09 21:39:54 INFO MemoryStore: MemoryStore cleared
20/04/09 21:39:54 INFO BlockManager: BlockManager stopped
20/04/09 21:39:54 INFO BlockManagerMaster: BlockManagerMaster stopped
20/04/09 21:39:54 INFO SparkContext: Successfully stopped SparkContext
20/04/09 21:39:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/04/09 21:39:54 INFO ShutdownHookManager: Shutdown hook called
20/04/09 21:39:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-57ede800-112d-461c-90bc-816f59b91ea2